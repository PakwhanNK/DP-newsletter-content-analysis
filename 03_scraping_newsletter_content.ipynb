{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOJR45tIxrXG0Gb4ny/TEsz",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PakwhanNK/DP-newsletter-content-analysis/blob/main/03_scraping_newsletter_content.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AfT3Cip_s_qm"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q beautifulsoup4 lxml requests tqdm"
   ],
   "metadata": {
    "id": "FTlTpXlttYh6"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from google.cloud import bigquery"
   ],
   "metadata": {
    "id": "h9BUhI5Rth8f"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "PROJECT_ID = userdata.get('PROJECT_ID')\n",
    "DATASET_ID = userdata.get('DATASET_ID')\n",
    "client = bigquery.Client(project=PROJECT_ID)\n"
   ],
   "metadata": {
    "id": "TsizGxEQtkZ4"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get campaigns with archive URLs\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    id as campaign_id,\n",
    "    subject_line,\n",
    "    send_time,\n",
    "    archive_url,\n",
    "    long_archive_url\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.campaign`\n",
    "WHERE\n",
    "    status = 'sent'\n",
    "    AND archive_url IS NOT NULL\n",
    "    AND send_time >= '2023-01-01'  -- Last 2 years\n",
    "ORDER BY send_time DESC\n",
    "LIMIT 200  -- Start with 200\n",
    "\"\"\"\n",
    "\n",
    "df_campaigns = client.query(query).to_dataframe()\n",
    "\n",
    "print(f\"‚úÖ Found {len(df_campaigns)} campaigns with URLs\")\n",
    "print(f\"\\nSample URL: {df_campaigns['archive_url'].iloc[0]}\")\n",
    "\n",
    "df_campaigns.head()"
   ],
   "metadata": {
    "id": "oL6ryMn2t0W_",
    "outputId": "bb525158-f425-4dfc-dbaf-58b1f13035e0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "‚úÖ Found 200 campaigns with URLs\n",
      "\n",
      "Sample URL: http://eepurl.com/jrnaSM\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  campaign_id                                       subject_line  \\\n",
       "0  40a96da39f             Your Weekly Toast: On the Boarder‚Äìline   \n",
       "1  08658dfd18  Voices of Penn: Mamdani's victory, grade infla...   \n",
       "2  11c93987eb           üèà Quaker Nation: 2025 Homecoming Preview   \n",
       "3  ca0867c19a  Friday Morning: Men‚Äôs basketball using NIL col...   \n",
       "4  bb9392f0ac           üèÄ Quaker Nation: 2025 Basketball Preview   \n",
       "\n",
       "                  send_time               archive_url  \\\n",
       "0 2025-11-07 15:00:00+00:00  http://eepurl.com/jrnaSM   \n",
       "1 2025-11-07 13:00:00+00:00  http://eepurl.com/jrolUM   \n",
       "2 2025-11-07 12:00:00+00:00  http://eepurl.com/jrn9FA   \n",
       "3 2025-11-07 11:00:00+00:00  http://eepurl.com/jrn_vI   \n",
       "4 2025-11-06 12:00:00+00:00  http://eepurl.com/jrhwlw   \n",
       "\n",
       "                                    long_archive_url  \n",
       "0  https://mailchi.mp/thedp/your-weekly-toast-606...  \n",
       "1  https://mailchi.mp/thedp/voices-of-penn-tktktk...  \n",
       "2  https://mailchi.mp/thedp/quaker-nation-april-6...  \n",
       "3  https://mailchi.mp/thedp/friday-morning-campus...  \n",
       "4  https://mailchi.mp/thedp/quaker-nation-april-6...  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-b9baf082-7dfe-42a3-9e93-3e17eea1a25b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>subject_line</th>\n",
       "      <th>send_time</th>\n",
       "      <th>archive_url</th>\n",
       "      <th>long_archive_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40a96da39f</td>\n",
       "      <td>Your Weekly Toast: On the Boarder‚Äìline</td>\n",
       "      <td>2025-11-07 15:00:00+00:00</td>\n",
       "      <td>http://eepurl.com/jrnaSM</td>\n",
       "      <td>https://mailchi.mp/thedp/your-weekly-toast-606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08658dfd18</td>\n",
       "      <td>Voices of Penn: Mamdani's victory, grade infla...</td>\n",
       "      <td>2025-11-07 13:00:00+00:00</td>\n",
       "      <td>http://eepurl.com/jrolUM</td>\n",
       "      <td>https://mailchi.mp/thedp/voices-of-penn-tktktk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11c93987eb</td>\n",
       "      <td>üèà Quaker Nation: 2025 Homecoming Preview</td>\n",
       "      <td>2025-11-07 12:00:00+00:00</td>\n",
       "      <td>http://eepurl.com/jrn9FA</td>\n",
       "      <td>https://mailchi.mp/thedp/quaker-nation-april-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca0867c19a</td>\n",
       "      <td>Friday Morning: Men‚Äôs basketball using NIL col...</td>\n",
       "      <td>2025-11-07 11:00:00+00:00</td>\n",
       "      <td>http://eepurl.com/jrn_vI</td>\n",
       "      <td>https://mailchi.mp/thedp/friday-morning-campus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb9392f0ac</td>\n",
       "      <td>üèÄ Quaker Nation: 2025 Basketball Preview</td>\n",
       "      <td>2025-11-06 12:00:00+00:00</td>\n",
       "      <td>http://eepurl.com/jrhwlw</td>\n",
       "      <td>https://mailchi.mp/thedp/quaker-nation-april-6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9baf082-7dfe-42a3-9e93-3e17eea1a25b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b9baf082-7dfe-42a3-9e93-3e17eea1a25b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b9baf082-7dfe-42a3-9e93-3e17eea1a25b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-4f94b9f8-05a0-4bd2-8813-940662815019\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f94b9f8-05a0-4bd2-8813-940662815019')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-4f94b9f8-05a0-4bd2-8813-940662815019 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df_campaigns",
       "summary": "{\n  \"name\": \"df_campaigns\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"campaign_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"005d744b7d\",\n          \"1c53d470e1\",\n          \"9a5adcff35\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_line\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"Monday Morning: Meet Penn\\u2019s Fulbright recipients\",\n          \"Voices of Penn: Don\\u2019t apply early\",\n          \"\\ud83c\\udfc3\\u200d\\u2642\\ufe0fQuaker Nation: Kampton Kam makes history again\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"send_time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-04-18 14:00:00+00:00\",\n        \"max\": \"2025-11-07 15:00:00+00:00\",\n        \"num_unique_values\": 190,\n        \"samples\": [\n          \"2025-04-28 14:00:00+00:00\",\n          \"2025-04-25 10:00:00+00:00\",\n          \"2025-09-04 10:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"archive_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"http://eepurl.com/jnz6Qw\",\n          \"http://eepurl.com/jqImHs\",\n          \"http://eepurl.com/jqd3H2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"long_archive_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"https://mailchi.mp/thedp/quaker-nation-april-6062171\",\n          \"https://mailchi.mp/thedp/your-weekly-toast-6062440\",\n          \"https://mailchi.mp/thedp/double-your-gift-to-penns-watchdog-6062408\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test on the most recent newsletter\n",
    "test_url = df_campaigns['archive_url'].iloc[0]\n",
    "print(f\"üîç Testing scrape on: {test_url}\\n\")\n",
    "\n",
    "# Fetch the HTML\n",
    "response = requests.get(test_url, timeout=10)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # See the structure\n",
    "    print(\"\\nüìÑ HTML Title:\", soup.title.string if soup.title else \"No title\")\n",
    "    print(f\"üìÑ Total HTML length: {len(response.text):,} characters\")\n",
    "\n",
    "    # Preview raw HTML (first 500 chars)\n",
    "    print(\"\\nüîç HTML Preview:\")\n",
    "    print(response.text[:500])\n",
    "else:\n",
    "    print(f\"‚ùå Failed to fetch. Status: {response.status_code}\")"
   ],
   "metadata": {
    "id": "Z9ZCp7xGuCOA",
    "outputId": "6f445d11-0ad9-4fba-c290-f9911e933a74",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç Testing scrape on: http://eepurl.com/jrnaSM\n",
      "\n",
      "Status Code: 200\n",
      "\n",
      "üìÑ HTML Title: Your Weekly Toast: On the Boarder‚Äìline\n",
      "üìÑ Total HTML length: 101,126 characters\n",
      "\n",
      "üîç HTML Preview:\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n",
      "<!doctype html>\n",
      "<html xmlns:fb=\"http://www.facebook.com/2008/fbml\" xmlns:og=\"http://opengraph.org/schema/\"> <head>\n",
      "        \n",
      "<meta property=\"og:title\" content=\"Your Weekly Toast: On the Boarder‚Äìline\">\n",
      "<meta property=\"fb:page_id\" content=\"43929265776\">\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\">\n",
      "<meta name=\"referrer\" content=\"origin\">        \n",
      "        <!-- NAME: 1 COL\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Look at the HTML structure to find main content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Check for common container elements\n",
    "print(\"Looking for main content containers...\\n\")\n",
    "\n",
    "# Try different selectors\n",
    "containers = [\n",
    "    ('div with id=\"content\"', soup.find('div', id='content')),\n",
    "    ('div with class=\"content\"', soup.find('div', class_='content')),\n",
    "    ('article tag', soup.find('article')),\n",
    "    ('main tag', soup.find('main')),\n",
    "    ('div with id=\"main\"', soup.find('div', id='main')),\n",
    "    ('div with class=\"mcnTextContent\"', soup.find('div', class_='mcnTextContent')),  # Mailchimp common\n",
    "]\n",
    "\n",
    "for name, element in containers:\n",
    "    if element:\n",
    "        text = element.get_text(strip=True)\n",
    "        print(f\"‚úÖ {name}: {len(text)} characters\")\n",
    "        print(f\"   Preview: {text[:100]}...\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: Not found\")\n",
    "\n",
    "# Show all div classes (helps identify Mailchimp structure)\n",
    "print(\"\\nüìã All div classes found:\")\n",
    "all_divs = soup.find_all('div', class_=True)\n",
    "classes = set()\n",
    "for div in all_divs[:20]:  # First 20\n",
    "    classes.update(div.get('class', []))\n",
    "\n",
    "for cls in sorted(classes):\n",
    "    print(f\"  ‚Ä¢ {cls}\")"
   ],
   "metadata": {
    "id": "OHXB5iQ8uc72",
    "outputId": "ccf6e2d9-2507-45ff-94f4-bcab733005ca",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç Looking for main content containers...\n",
      "\n",
      "‚ùå div with id=\"content\": Not found\n",
      "‚ùå div with class=\"content\": Not found\n",
      "‚ùå article tag: Not found\n",
      "‚ùå main tag: Not found\n",
      "‚ùå div with id=\"main\": Not found\n",
      "‚ùå div with class=\"mcnTextContent\": Not found\n",
      "\n",
      "üìã All div classes found:\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's see what we're actually dealing with\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "print(\"üîç FULL HTML STRUCTURE ANALYSIS\\n\")\n",
    "\n",
    "# 1. Check the title\n",
    "print(f\"üìÑ Page Title: {soup.title.string if soup.title else 'No title'}\")\n",
    "print()\n",
    "\n",
    "# 2. Look at all the top-level tags\n",
    "print(\"üìã Top-level structure:\")\n",
    "for tag in soup.find_all(recursive=False):\n",
    "    print(f\"  <{tag.name}>\")\n",
    "print()\n",
    "\n",
    "# 3. Look inside body\n",
    "if soup.body:\n",
    "    print(\"üìã Direct children of <body>:\")\n",
    "    for tag in soup.body.find_all(recursive=False):\n",
    "        tag_info = f\"  <{tag.name}\"\n",
    "        if tag.get('id'):\n",
    "            tag_info += f' id=\"{tag.get(\"id\")}\"'\n",
    "        if tag.get('class'):\n",
    "            tag_info += f' class=\"{\" \".join(tag.get(\"class\"))}\"'\n",
    "        tag_info += \">\"\n",
    "        print(tag_info)\n",
    "    print()\n",
    "else:\n",
    "    print(\"‚ùå No body tag found!\")\n",
    "\n",
    "# 4. Find ALL tables (Mailchimp often uses tables for layout)\n",
    "tables = soup.find_all('table')\n",
    "print(f\"üìä Found {len(tables)} tables in the HTML\")\n",
    "if len(tables) > 0:\n",
    "    print(\"\\nTable IDs and Classes:\")\n",
    "    for i, table in enumerate(tables[:10]):  # First 10 tables\n",
    "        table_info = f\"  Table {i+1}:\"\n",
    "        if table.get('id'):\n",
    "            table_info += f' id=\"{table.get(\"id\")}\"'\n",
    "        if table.get('class'):\n",
    "            table_info += f' class=\"{\" \".join(table.get(\"class\"))}\"'\n",
    "        # Count text in this table\n",
    "        text = table.get_text(strip=True)\n",
    "        table_info += f\" ({len(text)} chars)\"\n",
    "        print(table_info)\n",
    "print()\n",
    "\n",
    "# 5. Find the table with MOST text (probably the main content!)\n",
    "print(\"üéØ Finding table with most content...\")\n",
    "max_text = 0\n",
    "max_table = None\n",
    "for table in tables:\n",
    "    text = table.get_text(strip=True)\n",
    "    if len(text) > max_text:\n",
    "        max_text = len(text)\n",
    "        max_table = table\n",
    "\n",
    "if max_table:\n",
    "    print(f\"‚úÖ Largest table has {max_text} characters\")\n",
    "    print(f\"   Classes: {max_table.get('class', 'None')}\")\n",
    "    print(f\"   ID: {max_table.get('id', 'None')}\")\n",
    "    print()\n",
    "    print(\"üìÑ First 300 characters from largest table:\")\n",
    "    print(max_table.get_text(strip=True)[:300])"
   ],
   "metadata": {
    "id": "3lpYUWMbujQk",
    "outputId": "fa49eeeb-973e-456f-ae22-85ce8b1cb38c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üîç FULL HTML STRUCTURE ANALYSIS\n",
      "\n",
      "üìÑ Page Title: Your Weekly Toast: On the Boarder‚Äìline\n",
      "\n",
      "üìã Top-level structure:\n",
      "  <html>\n",
      "\n",
      "üìã Direct children of <body>:\n",
      "  <span class=\"mcnPreviewText\">\n",
      "  <center>\n",
      "  <script>\n",
      "  <script>\n",
      "\n",
      "üìä Found 74 tables in the HTML\n",
      "\n",
      "Table IDs and Classes:\n",
      "  Table 1: id=\"bodyTable\" (5501 chars)\n",
      "  Table 2: (5501 chars)\n",
      "  Table 3: class=\"templateContainer\" (0 chars)\n",
      "  Table 4: class=\"mcnTextBlock\" (0 chars)\n",
      "  Table 5: class=\"mcnTextContentContainer\" (0 chars)\n",
      "  Table 6: class=\"templateContainer\" (18 chars)\n",
      "  Table 7: class=\"mcnImageBlock\" (0 chars)\n",
      "  Table 8: class=\"mcnImageContentContainer\" (0 chars)\n",
      "  Table 9: class=\"mcnTextBlock\" (18 chars)\n",
      "  Table 10: class=\"mcnTextContentContainer\" (18 chars)\n",
      "\n",
      "üéØ Finding table with most content...\n",
      "‚úÖ Largest table has 5501 characters\n",
      "   Classes: None\n",
      "   ID: bodyTable\n",
      "\n",
      "üìÑ First 300 characters from largest table:\n",
      "Friday, November 7Dear Penn,The moral of Avril Lavigne‚Äôs ‚ÄúSk8er Boi‚Äù¬†is that even skaters deserve love and respect, right?It‚Äôs been four consecutive days of midterms for me‚Äîyes, one per day all this week‚Äîwith another two outlines due this Friday and my manager¬†poking me about when my deliverables ar\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_text = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "print(f\"üìä Total text length: {len(all_text):,} characters\")\n",
    "print(f\"üìä Total words: {len(all_text.split()):,}\")\n",
    "print()\n",
    "print(\"üìÑ First 800 characters of ALL text:\")\n",
    "print(all_text[:800])\n",
    "print()\n",
    "print(\"üìÑ Last 500 characters of ALL text:\")\n",
    "print(all_text[-500:])"
   ],
   "metadata": {
    "id": "B6nbeVkDvnDO",
    "outputId": "e32e84f4-d937-47cb-b016-62e0ce30d7a9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "üìä Total text length: 5,687 characters\n",
      "üìä Total words: 969\n",
      "\n",
      "üìÑ First 800 characters of ALL text:\n",
      "Your Weekly Toast: On the Boarder‚Äìline This newsletter contains real medical advice from unlicensed psychiatrist Nishanth Bhargava. Friday, November 7 Dear Penn, The moral of Avril Lavigne‚Äôs ‚ÄúSk8er Boi‚Äù¬†is that even skaters deserve love and respect, right? It‚Äôs been four consecutive days of midterms for me‚Äîyes, one per day all this week‚Äîwith another two outlines due this Friday and my manager¬†poking me about when my deliverables are coming in. The blows just don‚Äôt¬†seem to stop coming.¬†I‚Äôd say my life has been one battle after another,¬†but that feels disrespectful to Leonardo DiCaprio. After a stressful day, the one thing that helps me unwind is hitting the open road. The moment that highway opens up before me, all my worries melt away. My foot sinks gently into the gas pedal. The sea¬†of ca\n",
      "\n",
      "üìÑ Last 500 characters of ALL text:\n",
      "kicked off this Thursday, but you can catch screenings all through this weekend and the next. Today‚Äôs newsletter was copy edited by Jessica Huang. Are you enjoying this newsletter? Please share any ideas or concerns with Digital Managing Editor Nishanth Bhargava at streedigitaled@dailypennsylvanian.com The Toast is published every Friday by 34th Street Magazine.¬†You¬†can update your subscription preferences or unsubscribe at any time. Copyright ¬© 2025 The Daily Pennsylvanian, All rights reserved.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "-rKD6Fcjwodr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Build Content Extraction Function",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def extract_newsletter_content(url, timeout=10):\n    \"\"\"\n    Extract content from a Mailchimp newsletter archive URL.\n    \n    Returns dict with:\n    - text: main body text\n    - links: list of external links with their text\n    - word_count: number of words\n    - char_count: number of characters\n    \"\"\"\n    try:\n        response = requests.get(url, timeout=timeout)\n        \n        if response.status_code != 200:\n            return {'error': f'HTTP {response.status_code}'}\n        \n        soup = BeautifulSoup(response.content, 'html.parser')\n        \n        # Extract all text\n        full_text = soup.get_text(separator=' ', strip=True)\n        \n        # Clean up the text\n        full_text = re.sub(r'\\s+', ' ', full_text).strip()\n        \n        # Extract all links\n        links = []\n        for link in soup.find_all('a', href=True):\n            href = link['href']\n            link_text = link.get_text(strip=True)\n            \n            # Filter out mailchimp/unsubscribe links\n            if not any(skip in href.lower() for skip in ['mailchimp.com', 'unsubscribe', 'preferences', 'mailto:']):\n                if link_text:  # Only include links with text\n                    links.append({\n                        'url': href,\n                        'text': link_text\n                    })\n        \n        return {\n            'text': full_text,\n            'links': links,\n            'word_count': len(full_text.split()),\n            'char_count': len(full_text),\n            'link_count': len(links),\n            'error': None\n        }\n    \n    except Exception as e:\n        return {'error': str(e)}\n\n# Test the function\nprint(\"Testing extraction function...\\n\")\ntest_result = extract_newsletter_content(df_campaigns['archive_url'].iloc[0])\n\nif test_result.get('error'):\n    print(f\"‚ùå Error: {test_result['error']}\")\nelse:\n    print(f\"‚úÖ Successfully extracted:\")\n    print(f\"   ‚Ä¢ Text length: {test_result['char_count']:,} characters\")\n    print(f\"   ‚Ä¢ Word count: {test_result['word_count']:,} words\")\n    print(f\"   ‚Ä¢ Links found: {test_result['link_count']}\")\n    print(f\"\\nüìÑ First 300 characters:\")\n    print(test_result['text'][:300])\n    print(f\"\\nüîó Sample links:\")\n    for link in test_result['links'][:5]:\n        print(f\"   ‚Ä¢ {link['text'][:50]}: {link['url']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Scrape All Campaigns",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Scrape content from all campaigns\nprint(f\"üöÄ Scraping {len(df_campaigns)} campaigns...\\n\")\n\nresults = []\nerrors = []\n\nfor idx, row in tqdm(df_campaigns.iterrows(), total=len(df_campaigns)):\n    campaign_id = row['campaign_id']\n    url = row['archive_url']\n    \n    # Extract content\n    content = extract_newsletter_content(url)\n    \n    # Store result\n    result = {\n        'campaign_id': campaign_id,\n        'subject_line': row['subject_line'],\n        'send_time': row['send_time'],\n        'archive_url': url,\n        'word_count': content.get('word_count'),\n        'char_count': content.get('char_count'),\n        'link_count': content.get('link_count'),\n        'full_text': content.get('text'),\n        'links': content.get('links', []),\n        'error': content.get('error')\n    }\n    \n    results.append(result)\n    \n    if content.get('error'):\n        errors.append({'campaign_id': campaign_id, 'error': content.get('error')})\n    \n    # Be polite to the server\n    time.sleep(0.5)\n\ndf_content = pd.DataFrame(results)\n\nprint(f\"\\n‚úÖ Successfully scraped {len(df_content[df_content['error'].isna()])} campaigns\")\nprint(f\"‚ùå Failed to scrape {len(errors)} campaigns\")\n\nif errors:\n    print(\"\\n‚ùå Errors:\")\n    for err in errors[:5]:\n        print(f\"   ‚Ä¢ {err['campaign_id']}: {err['error']}\")\n\ndf_content.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Get Engagement Metrics from BigQuery",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Get campaign engagement metrics\nquery = f\"\"\"\nWITH campaign_stats AS (\n  SELECT\n    campaign_id,\n    COUNT(DISTINCT email_address) as recipients,\n    COUNT(DISTINCT CASE WHEN activity_type = 'open' THEN email_address END) as opens,\n    COUNT(DISTINCT CASE WHEN activity_type = 'click' THEN email_address END) as clicks\n  FROM `{PROJECT_ID}.{DATASET_ID}.campaign_recipient_activity`\n  GROUP BY campaign_id\n)\n\nSELECT\n  c.id as campaign_id,\n  c.subject_line,\n  c.send_time,\n  COALESCE(cs.recipients, 0) as recipients,\n  COALESCE(cs.opens, 0) as unique_opens,\n  COALESCE(cs.clicks, 0) as unique_clicks,\n  ROUND(SAFE_DIVIDE(cs.opens, cs.recipients) * 100, 2) as open_rate_pct,\n  ROUND(SAFE_DIVIDE(cs.clicks, cs.recipients) * 100, 2) as click_rate_pct,\n  ROUND(SAFE_DIVIDE(cs.clicks, cs.opens) * 100, 2) as ctr_pct\nFROM `{PROJECT_ID}.{DATASET_ID}.campaign` c\nLEFT JOIN campaign_stats cs ON c.id = cs.campaign_id\nWHERE\n  c.status = 'sent'\n  AND c.archive_url IS NOT NULL\n  AND c.send_time >= '2023-01-01'\nORDER BY c.send_time DESC\nLIMIT 200\n\"\"\"\n\nprint(\"üìä Fetching engagement metrics from BigQuery...\\n\")\ndf_metrics = client.query(query).to_dataframe()\n\nprint(f\"‚úÖ Retrieved metrics for {len(df_metrics)} campaigns\\n\")\nprint(\"üìà Summary statistics:\")\nprint(df_metrics[['open_rate_pct', 'click_rate_pct', 'ctr_pct']].describe())\n\ndf_metrics.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Combine Content and Engagement Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Merge content with engagement metrics\ndf_combined = df_content.merge(\n    df_metrics[['campaign_id', 'recipients', 'unique_opens', 'unique_clicks', \n                'open_rate_pct', 'click_rate_pct', 'ctr_pct']],\n    on='campaign_id',\n    how='left'\n)\n\n# Filter out campaigns with errors\ndf_combined = df_combined[df_combined['error'].isna()].copy()\n\nprint(f\"‚úÖ Combined dataset: {len(df_combined)} campaigns\\n\")\n\n# Add derived features\ndf_combined['send_date'] = pd.to_datetime(df_combined['send_time']).dt.date\ndf_combined['send_hour'] = pd.to_datetime(df_combined['send_time']).dt.hour\ndf_combined['send_day_of_week'] = pd.to_datetime(df_combined['send_time']).dt.day_name()\n\n# Calculate links per word ratio\ndf_combined['links_per_100_words'] = (df_combined['link_count'] / df_combined['word_count'] * 100).round(2)\n\nprint(\"üìä Dataset shape:\", df_combined.shape)\nprint(\"\\nüìà Column summary:\")\nprint(df_combined.columns.tolist())\n\n# Show sample with key metrics\ndisplay_cols = ['subject_line', 'word_count', 'link_count', 'open_rate_pct', 'click_rate_pct', 'ctr_pct']\ndf_combined[display_cols].head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Extract Link-Level Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create a detailed links dataset\nlink_records = []\n\nfor idx, row in df_combined.iterrows():\n    campaign_id = row['campaign_id']\n    subject = row['subject_line']\n    send_time = row['send_time']\n    \n    # Extract each link\n    for link in row['links']:\n        link_records.append({\n            'campaign_id': campaign_id,\n            'subject_line': subject,\n            'send_time': send_time,\n            'link_url': link['url'],\n            'link_text': link['text']\n        })\n\ndf_links = pd.DataFrame(link_records)\n\nprint(f\"üìä Extracted {len(df_links)} links from {df_combined['campaign_id'].nunique()} campaigns\\n\")\n\n# Identify the most common link domains\ndf_links['domain'] = df_links['link_url'].apply(\n    lambda x: re.findall(r'https?://([^/]+)', x)[0] if re.findall(r'https?://([^/]+)', x) else 'unknown'\n)\n\nprint(\"üîó Top 10 linked domains:\")\nprint(df_links['domain'].value_counts().head(10))\n\ndf_links.head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Save Processed Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Save the datasets\n\n# 1. Main campaign dataset (without the full text for now)\ndf_export = df_combined.drop(columns=['links', 'error']).copy()\n\nprint(\"üíæ Saving datasets...\\n\")\n\n# Save as CSV\ndf_export.to_csv('newsletter_campaigns_with_metrics.csv', index=False)\nprint(f\"‚úÖ Saved main dataset: newsletter_campaigns_with_metrics.csv ({len(df_export)} rows)\")\n\n# Save links dataset\ndf_links.to_csv('newsletter_links.csv', index=False)\nprint(f\"‚úÖ Saved links dataset: newsletter_links.csv ({len(df_links)} rows)\")\n\n# Optional: Save with full text as pickle (preserves all data types)\ndf_combined.to_pickle('newsletter_campaigns_full.pkl')\nprint(f\"‚úÖ Saved full dataset with text: newsletter_campaigns_full.pkl\")\n\nprint(\"\\nüìä Dataset Summary:\")\nprint(f\"   ‚Ä¢ Total campaigns: {len(df_combined)}\")\nprint(f\"   ‚Ä¢ Date range: {df_combined['send_date'].min()} to {df_combined['send_date'].max()}\")\nprint(f\"   ‚Ä¢ Total links extracted: {len(df_links)}\")\nprint(f\"   ‚Ä¢ Average word count: {df_combined['word_count'].mean():.0f}\")\nprint(f\"   ‚Ä¢ Average link count: {df_combined['link_count'].mean():.1f}\")\nprint(f\"\\nüìà Engagement Summary:\")\nprint(f\"   ‚Ä¢ Average open rate: {df_combined['open_rate_pct'].mean():.2f}%\")\nprint(f\"   ‚Ä¢ Average click rate: {df_combined['click_rate_pct'].mean():.2f}%\")\nprint(f\"   ‚Ä¢ Average CTR: {df_combined['ctr_pct'].mean():.2f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Next Steps for Analysis\n\nWith this data, you can now:\n\n1. **Content Analysis**\n   - Analyze which topics/keywords correlate with higher CTR\n   - Study subject line patterns (length, emoji usage, question marks)\n   - Examine link density vs engagement\n\n2. **Temporal Analysis**\n   - Best day/time to send newsletters\n   - Trends over time in engagement\n   - Seasonal patterns\n\n3. **NLP Features**\n   - Sentiment analysis of newsletter content\n   - Topic modeling with LDA or similar\n   - Extract entities (people, places, events)\n   - Readability scores\n\n4. **Predictive Modeling**\n   - Build models to predict click-through rates\n   - Feature importance analysis\n   - A/B test insights\n\n5. **Link Analysis**\n   - Which domains get the most clicks?\n   - Link placement effects\n   - Optimal number of links per newsletter",
   "metadata": {}
  }
 ]
}